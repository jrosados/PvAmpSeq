---
title: "Sensitivity analysis Solomon Islands: baseline allele frequencies"
author: "Shazia Ruybal-Pes√°ntez"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide 
    code_download: true
    fig_width: 8
    fig_height: 6
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(janitor)
library(here)
library(patchwork)
library(RColorBrewer)
library(reshape2)

# install.packages('Pv3Rs', repos = c('https://plasmogenepi.r-universe.dev', 'https://cloud.r-project.org'))

# devtools::install_github("aimeertaylor/Pv3Rs")
# Pv3Rs downloaded from Github on 7 Aug 2024
library(Pv3Rs)

set.seed(55)
```

## Set global variables
From TO/JS - This section sets some flags that can be tweaked to re-run the analysis with different filtering parameters:

`RUN_EXAMPLE`: allows discarding alleles that have a frequency below a threshold (defaults to FALSE),
`WITHIN_INDIVIDUAL_ALLELE_FREQ_THR`: allows discarding alleles that have a frequency below a threshold (defaults to 0),
`BENCHMARK_MARKERS`: list of markers to include in the analysis (defaults to the full list established by Jason, could be reduced down to 3 for memory optimization),
`MAX_MOI_TO_INCLUDE`: allows discarding participant data when they exhibit very complex infection patterns, counted as the total number of clones across all infection events (defaults to 8),
`PRIOR_3RS`: a named vector with prior probabilities of recrudescence (C), relapse (L) or reinfection (I) (defaults to uniform, i.e. 1/3 each, but tweaked to minimize recrudescence in the present study).

```{r global vars}
## RUN_EXAMPLE
##   Boolean flag to enable/disable running the example Pv3Rs posterior 
##   computation on a single episode sampled at random from the dataset.
## DEFAULT: FALSE
RUN_EXAMPLE <- TRUE

## WITHIN_INDIVIDUAL_ALLELE_FREQ_THR
##   Minimum threshold above which an allele is preserved in individual
##   haplotype data to be preserved when reconstructing infection 
##   history. Note that this will *not* discard these alleles from the
##   population-level allele frequency that is derived from the initial
##   visit, but only discard that allele from individual observations 
##   when it is 'too rare to be exploited'.
## DEFAULT: 0
WITHIN_INDIVIDUAL_ALLELE_FREQ_THR <- 0

## BENCHMARK_MARKERS
##   Vector of character string with names matching those from the 
##   markers of interest for amplicon sequencing. Only the markers 
##   listed in that vector will be preserved in individual-level data
##   and identity of infection will be solely based on the alleles 
##   observed for these markers.
##   The markers are listed by importance as discovered by Jason.
## DEFAULT: all markers (could be suboptimal/too memory-consuming?)
BENCHMARK_MARKERS <- c(
  "Chr05",
  "Chr07", 
  "Chr09", 
  "Chr10",
  "Chr08",
  "Chr13",
  "Chr11",
  "Chr03",
  "Chr01",
  "Chr02",
  "Chr14"
)

## MAX_MOI_TO_INCLUDE
##   As per Aimee's guidelines: 
##     We do not recommend running compute_posterior() for data 
##     whose total genotype count exceeds eight, where the total 
##     genotype count is the sum of per-episode maximum per-marker 
##     allele counts.
##   The MAX_MOI_TO_INCLUDE expects an integer that will discard all
##   individuals having a summed MOI > 8 across all recorded episodes.
## DEFAULT: 8
MAX_MOI_TO_INCLUDE <- 8

## PRIORS_3RS
##   A vector of probabilities, summing to 1, corresponding to 
##   the probability of each stage for the 3Rs for Pv episodes.
##   The vector order is re(C)rudescence, re(L)apse, re(I)nfection.
##   In this clinical trial, we assume recrudescence is possible so, 
##   we use the default priors 
## DEFAULT: c("C" = 1/3, "L" = 1/3, "I" = 1/3)
PRIOR_3RS <- c("C" = 1/3, "L" = 1/3, "I" = 1/3)
# Note: the below probabilities were used for SeroTAT study because it does not involve treatment at baseline
# PRIOR_3RS <- c("C" = 0.10, "L" = 0.45, "I" = 0.45)
```

## Solomon Islands data curation

Read in data from Solomon Islands:
```{r load data}
sols <- read.csv(here("data/final", "sols_raw_data.csv"))

# head(sols)
# names(sols)
```

### True recurrences
Participants with more than one episode for inference (n=41 participants, n=99 Pv isolates):
```{r recurrences}
# sols %>% 
#   select(info, episodes) %>% 
#   distinct() %>% 
#   arrange(info) %>% 
#   filter(episodes>1) 

ids_recurrent <- sols %>% clean_names() %>% filter(episodes > 1) %>% distinct(info)
sols_recurrent <- sols %>% clean_names() %>% filter(episodes > 1)

# setdiff(ids_recurrent$info, sols_recurrent$info)
# setdiff(sols_recurrent$info, ids_recurrent$info)

# sols_recurrent %>% distinct(sample) %>% arrange(sample) # 99 isolates
```

```{r plot recurrences, fig.height=8, fig.width=8}
sols_recurrent %>% 
  distinct(sample) %>% 
  separate(sample, into = c("sample", "episode_day"), sep = "-(?=[0-9]+$)") %>% 
  left_join(sols_recurrent %>% distinct(info, trt_label, trtgrp), by = c("sample" = "info")) %>%  
  ggplot(aes(x = as.numeric(episode_day), y = reorder(sample, as.numeric(episode_day)))) +
    geom_line(aes(group = sample), color = "darkgrey") +
    geom_point() +
    scale_x_continuous(breaks = scales::pretty_breaks(n=10)) +
    labs(x = "time since baseline episode",
         y = "sample") +
    theme_bw() +
    facet_grid(trt_label~., scales = "free_y") 
```

### Data on episode number and time since last episode
```{r episode summary}
episode_summary <- sols_recurrent %>% 
  distinct(info, info_d, vis_date, sample) %>% 
  mutate(vis_date = mdy(vis_date)) %>%
  arrange(info, vis_date) %>% 
  group_by(info) %>% 
  mutate(
    # get the episode number
    episode_number = row_number(),
    # calculate days since enrolment, just a check with dates
    days_since_enrolment = as.integer(vis_date - min(vis_date[info_d == 0])),
    # calculate days since last episode using lag() and making enrolment episodes 0 days since last
    days_since_last_episode = replace_na(as.integer(vis_date - lag(vis_date)), 0)
  ) %>% 
  ungroup()
```

## Haplotype frequencies
We want to remove any haplotypes that appear only once at very low frequencies. Haplotypes should already be filtered to be observed in at least 2 samples and within-host frequency >=1% (in full dataset).
```{r singletons}
singleton_haps <- sols_recurrent %>% 
  select(sample, marker_id, haplotype, frequency, count) %>% 
  count(haplotype) %>% 
  arrange(n) %>% 
  filter(n==1) %>% 
  pull(haplotype)

sols_recurrent %>%
  filter(haplotype %in% singleton_haps) %>%
  ggplot(aes(x = haplotype, y = count)) +
    geom_hline(yintercept = 100, linetype = "dashed") +
    geom_point(aes(color = frequency, shape = follow_x), size = 3) +
    labs(x = "singleton haplotype",
         y = "read count",
         color = "within-sample frequency",
         shape = "timepoint") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

## **Sensitivity analysis**: Haplotypes for inference based on ALL samples
As per Aimee, to avoid bias due to within-host selection of recrudescent parasites, we used only enrolment episodes to estimate population-level alelle frequencies. However, we now run a sensitivity analysis to see if the results change if we use all episodes rather than just baseline. 
```{r haps for inference}
# n=1281 haps
all_haps <- sols_recurrent %>% 
  # filter(episode_type == "baseline") %>% 
  pull(haplotype)
```

## Final data for inference
```{r final analysis data}
analysis_data <- sols_recurrent %>%
  select(subject_id = info, 
         sample_id = sample, 
         treatment_arm = trt_label, 
         days_since_treatment = info_d,
         timepoint = follow_x,
         visit_date = vis_date,
         age_years = age_y, 
         sex = gender, 
         episodes,
         marker_id, 
         haplotype, 
         type,
         frequency,
         mean_moi,
         max_moi) %>% 
  # add extra epi info on episode number and time since last episode
  left_join(episode_summary %>% select(subject_id = info, 
                                       sample_id = sample, 
                                       episode_number,
                                       days_since_enrolment,
                                       days_since_last_episode),
            by = c("subject_id", "sample_id"))  %>% 
  # keep only haplotypes present at baseline
  # filter(haplotype %in% baseline_haps) %>% 
  # ensure dates are date class
  mutate(visit_date = mdy(visit_date)) 
```

### **Sensitivity analysis**: Baseline allele frequencies based on ALL samples
```{r baseline allele freqs}
## Derive baseline allele frequency - This is modified from Thomas/Jason script for our data
baseline_fs <- analysis_data %>% 
  
  # Use only baseline samples
  # filter(timepoint == "baseline") %>% 
  
  # split data frame by marker
  group_by(marker_id) %>% 
  group_split() %>% 
  
  # Derive a within-marker list of frequencies, by individual
  lapply(function(x) {
    x <- x %>% 
      # Build a within-individual frequency table that 
      # always includes every haplotype (even the ones absent)
      mutate(haplotype = factor(haplotype)) %>% 
      select(sample_id, haplotype, frequency) %>% 
      pivot_wider(names_from = haplotype, 
                  values_from = frequency, 
                  values_fill = 0) %>% 
      pivot_longer(cols = -sample_id, 
                   names_to = "haplotype", 
                   values_to = "frequency") %>% 
      # Get population-level haplotype frequency, 
      # correcting for when within-individual sum is not equal 
      # to 1, as can happen when a minority clone is <2%
      group_by(sample_id) %>% 
      mutate(frequency = frequency / sum(frequency, na.rm = TRUE)) %>% 
      group_by(haplotype) %>% 
      summarise(frequency_pop_mean = mean(frequency, na.rm = TRUE))
    
    return(deframe(x))
  }) %>% 
  # get marker_id from group_keys from the group dfs 
  setNames(nm = analysis_data %>% group_by(marker_id) %>% group_keys() %>% pull(marker_id))

# Here we can also save as dataframe for easier printing and table-ready for paper
baseline_fs_df <- analysis_data %>% 
  # Use only baseline samples
  # filter(timepoint == "baseline") %>% 
  
  # Group by marker_id and sample_id for further calculations
  group_by(marker_id, sample_id) %>% 
  
  # Build a within-individual frequency table that always includes every haplotype (even the ones absent)
  mutate(haplotype = factor(haplotype)) %>% 
  select(marker_id, sample_id, haplotype, frequency) %>% 
  pivot_wider(names_from = haplotype, values_from = frequency, values_fill = list(frequency = 0)) %>% 
  pivot_longer(cols = -c(marker_id, sample_id), names_to = "haplotype", values_to = "frequency") %>% 
  
  # Get population-level haplotype frequency, correcting for when within-individual sum is not equal to 1
  group_by(marker_id, sample_id) %>% 
  mutate(frequency = frequency / sum(frequency, na.rm = TRUE)) %>% 
  group_by(marker_id, haplotype) %>% 
  summarise(frequency_pop_mean = mean(frequency, na.rm = TRUE), .groups = 'drop') %>% 
  
  # Ensure haplotypes are correctly associated with their marker_id - note that this works for us because , in future would have to make this flexible to allow for haplotype names that are not reliant on having marker_id
  filter(str_detect(haplotype, marker_id))

# baseline_fs_df
```

## Pv3Rs
### Example on one participant: AR-067
```{r pv3rs one example}
# This has been modified from Thomas/Jason script 

## Pick an individual at random to run Pv3Rs
# indiv_name <- sample(unique(analysis_data$subject_id), size = 1)
indiv_name <- "AR-067"

## Prepare the data
# 1- Subset haplotype data to specific individual and apply filters
indiv_haplotype_data <- analysis_data %>% 
  # Restrict to a single patient
  filter(subject_id == indiv_name) %>% 
  # Restrict to a subset of markers, if needed
  filter(marker_id %in% BENCHMARK_MARKERS) %>% 
  # Restrict to summed MOI below threshold
  group_by(subject_id, episode_number, marker_id) %>% 
  mutate(MOI_per_marker = sum(n())) %>% 
  group_by(subject_id, episode_number) %>% 
  mutate(MOI_per_episode = max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(marker_id = factor(marker_id, levels = BENCHMARK_MARKERS))

# 2- Calculate per-episode and per-participant MOI for PvR3S eligibility
indiv_MOI <- indiv_haplotype_data %>% 
  select(subject_id, episode_number, 
         marker_id, starts_with("MOI_")) %>% 
  distinct() %>% 
  group_by(subject_id, episode_number) %>% 
  # Get highest per-marker MOI only for each episode
  # (drop marker_id in case of ties with highest per-marker MOI)
  select(-marker_id) %>% 
  distinct() %>% 
  filter(MOI_per_marker == max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(MOI_summed = sum(MOI_per_episode, na.rm = TRUE))
```

Prepare test data
```{r}
# Finish data preparation
  indiv_haplotype_data <- indiv_haplotype_data %>% 
    group_by(episode_number) %>% 
    group_split() %>% 
    lapply(function(x) {
      res <- x %>% 
        select(sample_id, episode_number, 
               marker_id, haplotype, frequency) %>% 
        # For sensitivity analysis, allow to include/drop allele 
        # based on their within-individual frequency
        filter(frequency >= WITHIN_INDIVIDUAL_ALLELE_FREQ_THR) %>% 
        select(-sample_id, -episode_number, -frequency) %>% 
        distinct() %>% 
        # Prevent dropping of markers that are not characterised 
        # by setting .drop to FALSE
        group_by(marker_id, .drop = FALSE) %>% 
        group_split() %>% 
        lapply(function(y) {
          unique(y$haplotype)
        })
      
      # Returned a list named with each episode, 
      # setting marker allele to NA in case none are observed
      return(lapply(setNames(res, BENCHMARK_MARKERS), 
                    function(y) {
                      if (length(y) == 0) return(NA) else return(y)
                    }))
    })
```

```{r run compute posterior one indiv}
# Run Aimee's posterior estimation
indiv_posterior <- Pv3Rs::compute_posterior(y  = indiv_haplotype_data, 
                                            fs = baseline_fs[BENCHMARK_MARKERS])

indiv_posterior
```

The joint posterior probability of relapse is 99.9%, when we look at the genetic data, this is in line with the inferred probability of relpase (and is similar to that computed with only baseline frequencies - 99.7%)
```{r plot haps}
sols_recurrent %>% 
  filter(info== "AR-067") %>% 
  ggplot(aes(x = haplotype, y = factor(info_d), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free_x") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```
### Run Pv3Rs one random individual
```{r subset haplotype data at random}
# This has been modified from Thomas/Jason script 

## Pick an individual at random to run Pv3Rs
indiv_name <- sample(unique(analysis_data$subject_id), size = 1)

## Prepare the data
# 1- Subset haplotype data to specific individual and apply filters
indiv_haplotype_data <- analysis_data %>% 
  # Restrict to a single patient
  filter(subject_id == indiv_name) %>% 
  # Restrict to a subset of markers, if needed
  filter(marker_id %in% BENCHMARK_MARKERS) %>% 
  # Restrict to summed MOI below threshold
  group_by(subject_id, episode_number, marker_id) %>% 
  mutate(MOI_per_marker = sum(n())) %>% 
  group_by(subject_id, episode_number) %>% 
  mutate(MOI_per_episode = max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(marker_id = factor(marker_id, levels = BENCHMARK_MARKERS))

# 2- Calculate per-episode and per-participant MOI for PvR3S eligibility
indiv_MOI <- indiv_haplotype_data %>% 
  select(subject_id, episode_number, 
         marker_id, starts_with("MOI_")) %>% 
  distinct() %>% 
  group_by(subject_id, episode_number) %>% 
  # Get highest per-marker MOI only for each episode
  # (drop marker_id in case of ties with highest per-marker MOI)
  select(-marker_id) %>% 
  distinct() %>% 
  filter(MOI_per_marker == max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(MOI_summed = sum(MOI_per_episode, na.rm = TRUE))
```


Now that the data has been subset, Pv3Rs::compute_posterior() will be called (only if the participant meets eligibility criteria as defined by the global variables set earlier in this report).
```{r run Pv3Rs one random indiv, eval=F}
if (RUN_EXAMPLE & unique(indiv_MOI$MOI_summed) <= MAX_MOI_TO_INCLUDE) {
  # Verbose
  cat("Running Pv3Rs for: ", 
      indiv_name, 
      " (summed MOI = ", 
      unique(indiv_MOI$MOI_summed), 
      ").\n", 
      sep = "")
  
  # Finish data preparation
  indiv_haplotype_data <- indiv_haplotype_data %>% 
    group_by(episode_number) %>% 
    group_split() %>% 
    lapply(function(x) {
      res <- x %>% 
        select(sample_id, episode_number, 
               marker_id, haplotype, frequency) %>% 
        # For sensitivity analysis, allow to include/drop allele 
        # based on their within-individual frequency
        filter(frequency >= WITHIN_INDIVIDUAL_ALLELE_FREQ_THR) %>% 
        select(-sample_id, -episode_number, -frequency) %>% 
        distinct() %>% 
        # Prevent dropping of markers that are not characterised 
        # by setting .drop to FALSE
        group_by(marker_id, .drop = FALSE) %>% 
        group_split() %>% 
        lapply(function(y) {
          unique(y$haplotype)
        })
      
      # Returned a list named with each episode, 
      # setting marker allele to NA in case none are observed
      return(lapply(setNames(res, BENCHMARK_MARKERS), 
                    function(y) {
                      if (length(y) == 0) return(NA) else return(y)
                    }))
    })
  
  # Run Aimee's posterior estimation
  indiv_posterior <- Pv3Rs::compute_posterior(y  = indiv_haplotype_data, 
                                              fs = baseline_fs[BENCHMARK_MARKERS])
} else {
  # Verbose
  cat("NOT Running Pv3Rs for: ", 
      indiv_name, 
      " because either summed MOI exceeds threshold (observed = ", 
      unique(indiv_MOI$MOI_summed), 
      ", MAX_MOI_TO_INCLUDE = ", 
      MAX_MOI_TO_INCLUDE, 
      "), or RUN_EXAMPLE was set to FALSE.\n", 
      sep = "")
  
  # Return NULL
  indiv_posterior <- NULL
}

indiv_posterior
```

```{r plot haps for indiv, eval=F}
sols_recurrent %>% 
  filter(info == indiv_name) %>% 
  ggplot(aes(x = haplotype, y = factor(info_d), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free_x") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```
### Run for all participants
```{r run pv3rs all}
# Start timer
t_start <- Sys.time()

# Initialize an empty list to store the results
indiv_posteriors <- list()

# Loop through each unique individual name
for (indiv_name in unique(analysis_data$subject_id)) {
  # Verbose
  cat("ID : ", indiv_name, "...\n", sep = "")
  
  ## Prepare the data
  # 1- Subset haplotype data to specific individual and apply filters
  indiv_haplotype_data <- analysis_data %>% 
    # Restrict to a single patient
    filter(subject_id == indiv_name) %>% 
    # Ensure episodes are in order
    arrange(episode_number) %>%  
    # Restrict to a subset of markers
    filter(marker_id %in% BENCHMARK_MARKERS) %>% 
    # Restrict to summed MOI below threshold
    group_by(subject_id, episode_number, marker_id) %>% 
    mutate(MOI_per_marker = sum(n())) %>% 
    group_by(subject_id, episode_number) %>% 
    mutate(MOI_per_episode = max(MOI_per_marker, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(marker_id = factor(marker_id, levels = BENCHMARK_MARKERS))
  
  # 2- Calculate per-episode and per-participant MOI for PvR3S eligibility
  indiv_MOI <- indiv_haplotype_data %>% 
    select(subject_id, episode_number, 
           marker_id, starts_with("MOI_")) %>% 
    distinct() %>% 
    group_by(subject_id, episode_number) %>% 
    # Get highest per-marker MOI only for each episode
    # (drop marker_id in case of ties with highest per-marker MOI)
    select(-marker_id) %>% 
    distinct() %>% 
    filter(MOI_per_marker == max(MOI_per_marker, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(MOI_summed = sum(MOI_per_episode, na.rm = TRUE))
  
  ## Run Pv3Rs only if MOI below threshold         
  if (unique(indiv_MOI$MOI_summed) <= MAX_MOI_TO_INCLUDE) {
    # Verbose
    cat("Running Pv3Rs for: ", 
        indiv_name, 
        " (summed MOI = ", 
        unique(indiv_MOI$MOI_summed), 
        ").\n", 
        sep = "")
    
    # Preserve episode numbers for naming the output list
    indiv_episode <- unique(indiv_haplotype_data$episode_number)
    cat("The episode number is: ", indiv_episode) # printing to check episode order number is correct
    
    # Finish data preparation
    indiv_haplotype_data <- indiv_haplotype_data %>% 
      group_by(episode_number) %>% 
      group_split() %>% 
      lapply(function(x) {
        res <- x %>% 
          select(sample_id, episode_number, 
                 marker_id, haplotype, frequency) %>% 
          # For sensitivity analysis, allow to include/drop allele 
          # based on their within-individual frequency
          filter(frequency >= WITHIN_INDIVIDUAL_ALLELE_FREQ_THR) %>% 
          select(-sample_id, -episode_number, -frequency) %>% 
          distinct() %>% 
          # Prevent dropping of markers that are not characterized 
          # by setting .drop to FALSE
          group_by(marker_id, .drop = FALSE) %>% 
          group_split() %>% 
          lapply(function(y) {
            unique(y$haplotype)
          })
        
        # Returned a list named with each episode, 
        # setting marker allele to NA in case none are observed
        return(lapply(setNames(res, BENCHMARK_MARKERS), 
                      function(y) {
                        if (length(y) == 0) return(NA) else return(y)
                      }))
      })
    
    # Run Aimee's posterior estimation
    indiv_posterior <- compute_posterior(y     = indiv_haplotype_data,
                                         fs    = baseline_fs[BENCHMARK_MARKERS], 
                                         prior = matrix(PRIOR_3RS, 
                                                        nrow     = length(indiv_haplotype_data), 
                                                        ncol     = length(PRIOR_3RS), 
                                                        byrow    = TRUE, 
                                                        dimnames = list(c(1:length(indiv_haplotype_data)), 
                                                                        names(PRIOR_3RS))))
    
  } else {
    # Verbose
    cat("NOT Running Pv3Rs for: ", 
        indiv_name, 
        " because summed MOI exceeds threshold (observed = ", 
        unique(indiv_MOI$MOI_summed), 
        ", MAX_MOI_TO_INCLUDE = ", 
        MAX_MOI_TO_INCLUDE, 
        ").\n", 
        sep = "")
    
    # Return NULL
    indiv_episode    <- unique(indiv_haplotype_data$episode_number)
    indiv_posterior <- NULL
  }
  
  # Append the results to the list
  indiv_posteriors[[indiv_name]] <- list("subject_id" = indiv_name, 
                                         "episode_number"       = indiv_episode, 
                                         "Pv3Rs"       = indiv_posterior)
}

# End timer
t_end <- Sys.time()
cat("Pv3Rs for the whole dataset took : ", as.numeric(difftime(time1 = t_end, 
                                                               time2 = t_start, 
                                                               units = "secs"))/60, " mins", "\n", sep = "")

# Present the marginal data in a clearer format
indiv_posteriors_marginal <- do.call(rbind, 
                                     lapply(indiv_posteriors, function(x) {
                                       if (!is.null(x[["Pv3Rs"]])) {
                                         return(data.frame("subject_id"               = x[["subject_id"]], 
                                                           "episode_number"                     = x[["episode_number"]][-1], 
                                                           "Posterior_marginal_prob_C" = x[["Pv3Rs"]]$marg[, "C"], 
                                                           "Posterior_marginal_prob_L" = x[["Pv3Rs"]]$marg[, "L"], 
                                                           "Posterior_marginal_prob_I" = x[["Pv3Rs"]]$marg[, "I"]))
                                       } else {
                                         return(NULL)
                                       }
                                       
                                     }))
row.names(indiv_posteriors_marginal) <- 1:nrow(indiv_posteriors_marginal)

# Present the joint posterior estimates in a clearer format
indiv_posteriors_joint <- do.call(rbind, 
                                  lapply(indiv_posteriors, function(x) {
                                    if (!is.null(x[["Pv3Rs"]])) {
                                      joint_probs <- x[["Pv3Rs"]]$joint
                                      # Extract the state pairs and probabilities
                                      state_pairs <- names(joint_probs)
                                      prob_values <- as.numeric(joint_probs)
                                      
                                      # Create a data frame with subject_id, episode_number, and joint probabilities
                                      return(data.frame("subject_id"      = rep(x[["subject_id"]], length(state_pairs)), 
                                                        "episode_number"  = rep(x[["episode_number"]][-1], each = length(state_pairs)),
                                                        "state_pair"      = state_pairs, 
                                                        "joint_probability" = prob_values))
                                    } else {
                                      return(NULL)
                                    }
                                  }))
row.names(indiv_posteriors_joint) <- 1:nrow(indiv_posteriors_joint)

# Save Pv3Rs output because it's time consuming and 
# we don't want to re-run it every time.
save(list = c("RUN_EXAMPLE", "WITHIN_INDIVIDUAL_ALLELE_FREQ_THR", "BENCHMARK_MARKERS", "MAX_MOI_TO_INCLUDE", "PRIOR_3RS", 
              "analysis_data", "baseline_fs", 
              "indiv_posteriors", "indiv_posteriors_marginal", "indiv_posteriors_joint"), 
     file = paste0("./outputs/Pv3Rs_sols_posteriors_sensitivity_fs_all_", 
                   strftime(Sys.time(), format = "%Y%m%d_%H%M%S"), 
                   ".RData"))
```

### Explore the posterior
The marginal probabilities give us the probability of the three states for each recurrent episode. However, this does not consider the joint probability of different states when a person experienced more than one recurrent episode. 
```{r marginal probs}
indiv_posteriors_marginal
```

The joint probabilites give us values for each possible combination of states, depending on the number of recurrent episodes experienced by the participant. 
```{r joint probs}
joint_summary <- indiv_posteriors_joint %>% 
                    group_by(subject_id, state_pair, joint_probability) %>% 
                    filter(episode_number == max(episode_number)) %>% 
                    mutate(percentage = round(joint_probability*100, 3),
                           total_recurrences = episode_number-1) %>%
                    select(-episode_number) %>% 
                    arrange(subject_id, total_recurrences, percentage) %>% 
                    relocate(total_recurrences, .before = state_pair)

joint_summary
```

## Plot marginal probabilities 
```{r marg probs}
marginal_summary <- indiv_posteriors_marginal %>% 
  pivot_longer(cols = !subject_id & !episode_number, 
               names_to = "posterior_type", 
               values_to = "posterior_value") %>% 
  mutate(posterior_classification = case_when(posterior_type == "Posterior_marginal_prob_C" ~ "Recrudescence",
                                              posterior_type == "Posterior_marginal_prob_L" ~ "Relapse",
                                              posterior_type == "Posterior_marginal_prob_I" ~ "Reinfection"),
         posterior_classification = factor(posterior_classification, 
                                           levels = c("Relapse", "Recrudescence", "Reinfection"))) %>% 
  select(-posterior_type)

marginal_summary
```

### By participant
```{r plot probabilities, fig.height=8, fig.width=8}
marginal_summary %>% 
  group_by(subject_id) %>%
  arrange(desc(posterior_value), .by_group = TRUE) %>%
  mutate(subject_id = factor(subject_id, levels = unique(subject_id[order(posterior_value, decreasing = TRUE)]))) %>%
  
  ggplot(aes(x = factor(episode_number), y = posterior_value, group = episode_number, fill = posterior_classification)) + 
    geom_bar(stat = "identity", position = "fill") +
    scale_fill_manual(values = c("Relapse" = "turquoise3",
                                 "Recrudescence" = "skyblue4",
                                 "Reinfection" = "magenta3")) +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    labs(x     = "Episode number", 
         y     = "Posterior probability", 
         fill = "") + 
    theme_bw() +
    facet_wrap(~subject_id)
```

## Plot joint probabilities
```{r color palettes}
pal1 <- c(
  "C" = "turquoise3", 
  "I" = "magenta3", 
  "L" = "skyblue4")

pal2 <- c(
  "II" = "magenta3",
  "IL" = "darkorange2",
  "LI" = "goldenrod2",
  "LL" = "skyblue4",
  "CI" = "saddlebrown",
  "CL" = "turquoise4",
  "IC" = "darkolivegreen",
  "LC" = "lightseagreen"
)

pal3 <- c(
  "IIL" = "darkorange3",
  "ILL" = "orangered3",
  "LIL" = "goldenrod3",
  "LLL" = "skyblue4",
  "CCI" = "sienna4",
  "CCL" = "cadetblue3",
  "CLI" = "darkcyan",
  "CLL" = "steelblue3",
  "LCI" = "peru",
  "LCL" = "powderblue",
  "LLI" = "orange3"
)

pal4 <- c(
  "ICCI" = "saddlebrown",
  "ICCL" = "darkseagreen",
  "ICLI" = "orange3",
  "ICLL" = "lightsteelblue",
  "ILCI" = "darkkhaki",
  "ILCL" = "skyblue3",
  "ILLI" = "gold3",
  "LCCI" = "rosybrown",
  "LCCL" = "lightblue3",
  "LCLI" = "goldenrod3",
  "LCLL" = "deepskyblue3",
  "LLCI" = "tan",
  "LLCL" = "mediumturquoise",
  "LLLI" = "darkorange3"
)

combined_pal <- c(pal1, pal2, pal3, pal4)
```

```{r plotting joint fxn}
plotJointProb <- function(data, recurrence_n, prob_threshold, color_palette, ...){
  data %>% 
    filter(total_recurrences == recurrence_n, joint_probability > prob_threshold) %>% 
    group_by(subject_id) %>% 
    mutate(state_pair = fct_reorder(state_pair, joint_probability)) %>%
    ungroup() %>% 
    ggplot(aes(x = joint_probability, 
               y = subject_id, 
               fill = state_pair)) +
      geom_bar(position = "stack", stat = "identity") +
      scale_x_continuous(expand = c(0, 0)) +
      scale_y_discrete(expand = c(0, 0)) +
      scale_fill_manual(values = color_palette) +
      labs(x = "Joint probability estimate",
           y = "Participant",
           fill = "Classification state") +
      theme_bw() + 
    facet_wrap(~total_recurrences, scales = "free_y")
}
```

### By total number of recurrences
```{r plot joint by recurrences, fig.height = 7, fig.width = 12}
plot_joint1 <- plotJointProb(joint_summary, 1, 0, pal1) 
plot_joint2 <- plotJointProb(joint_summary, 2, 0, pal2) + guides(fill = guide_legend(ncol = 2)) 
plot_joint3 <- plotJointProb(joint_summary, 3, 0.001, pal3) + guides(fill = guide_legend(ncol = 3)) 
plot_joint4 <- plotJointProb(joint_summary, 4, 0.001, pal4) + guides(fill = guide_legend(ncol = 3)) 

(plot_joint1 | plot_joint2) / (plot_joint3 | plot_joint4) +
  plot_annotation(subtitle = "I = Reinfection, L = Relapse, C = Recrudescence",
                  caption = expression(italic("For >2 recurrences, only probability estimates > 0.001 are shown"))) +
  plot_layout(heights = c(2, 1))
```