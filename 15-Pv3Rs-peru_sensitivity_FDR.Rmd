---
title: "Running Pv3Rs for Peru data: false discovery rate"
author: "Shazia Ruybal-Pes√°ntez"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide 
    code_download: true
    fig_width: 8
    fig_height: 6
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(janitor)
library(here)
library(patchwork)
library(RColorBrewer)
library(reshape2)

# install.packages('Pv3Rs', repos = c('https://plasmogenepi.r-universe.dev', 'https://cloud.r-project.org'))

# devtools::install_github("aimeertaylor/Pv3Rs")
# Pv3Rs downloaded from Github on 7 Aug 2024
library(Pv3Rs)

set.seed(55)
```

## Set global variables
From TO/JS - This section sets some flags that can be tweaked to re-run the analysis with different filtering parameters:

`RUN_EXAMPLE`: allows discarding alleles that have a frequency below a threshold (defaults to FALSE),
`WITHIN_INDIVIDUAL_ALLELE_FREQ_THR`: allows discarding alleles that have a frequency below a threshold (defaults to 0),
`BENCHMARK_MARKERS`: list of markers to include in the analysis (defaults to the full list established by Jason, could be reduced down to 3 for memory optimization),
`MAX_MOI_TO_INCLUDE`: allows discarding participant data when they exhibit very complex infection patterns, counted as the total number of clones across all infection events (defaults to 8),
`PRIOR_3RS`: a named vector with prior probabilities of recrudescence (C), relapse (L) or reinfection (I) (defaults to uniform, i.e. 1/3 each, but tweaked to minimize recrudescence in the present study).

```{r global vars}
## RUN_EXAMPLE
##   Boolean flag to enable/disable running the example Pv3Rs posterior 
##   computation on a single episode sampled at random from the dataset.
## DEFAULT: FALSE
RUN_EXAMPLE <- TRUE

## WITHIN_INDIVIDUAL_ALLELE_FREQ_THR
##   Minimum threshold above which an allele is preserved in individual
##   haplotype data to be preserved when reconstructing infection 
##   history. Note that this will *not* discard these alleles from the
##   population-level allele frequency that is derived from the initial
##   visit, but only discard that allele from individual observations 
##   when it is 'too rare to be exploited'.
## DEFAULT: 0
WITHIN_INDIVIDUAL_ALLELE_FREQ_THR <- 0

## BENCHMARK_MARKERS
##   Vector of character string with names matching those from the 
##   markers of interest for amplicon sequencing. Only the markers 
##   listed in that vector will be preserved in individual-level data
##   and identity of infection will be solely based on the alleles 
##   observed for these markers.
##   The markers are listed by importance as discovered by Jason.
## DEFAULT: all markers (could be suboptimal/too memory-consuming?)
BENCHMARK_MARKERS <- c(
  "Chr05",
  "Chr07", 
  "Chr09", 
  "Chr10",
  "Chr08",
  "Chr13",
  "Chr11",
  "Chr03",
  "Chr01",
  "Chr02",
  "Chr14"
)

## MAX_MOI_TO_INCLUDE
##   As per Aimee's guidelines: 
##     We do not recommend running compute_posterior() for data 
##     whose total genotype count exceeds eight, where the total 
##     genotype count is the sum of per-episode maximum per-marker 
##     allele counts.
##   The MAX_MOI_TO_INCLUDE expects an integer that will discard all
##   individuals having a summed MOI > 8 across all recorded episodes.
## DEFAULT: 8
MAX_MOI_TO_INCLUDE <- 8

## PRIORS_3RS
##   A vector of probabilities, summing to 1, corresponding to 
##   the probability of each stage for the 3Rs for Pv episodes.
##   The vector order is re(C)rudescence, re(L)apse, re(I)nfection.
##   In this clinical trial, we assume recrudescence is possible so, 
##   we use the default priors 
## DEFAULT: c("C" = 1/3, "L" = 1/3, "I" = 1/3)
# PRIOR_3RS <- c("C" = 1/3, "L" = 1/3, "I" = 1/3)
# Note: the below probabilities were used for SeroTAT study because it does not involve treatment at baseline
# PRIOR_3RS <- c("C" = 0.10, "L" = 0.45, "I" = 0.45)
# We will use the same for the Peru community survey
PRIOR_3RS <- c("C" = 0.10, "L" = 0.45, "I" = 0.45)
```

## Peru data curation

Read in data from Peru:
```{r read peru data}
peru <- read.csv(here("data/final", "merged_PE.csv"))

# head(peru)
# names(peru)
```

### True recurrences
Participants with more than one episode for inference (n=41 participants, n=99 Pv isolates):
```{r recurrences}
peru %>% 
  select(PatientName, episodes) %>% 
  distinct() %>% 
  arrange(PatientName) %>% 
  filter(episodes>1) 

ids_recurrent <- peru %>% clean_names() %>% filter(episodes > 1) %>% distinct(patient_name)
peru_recurrent <- peru %>% clean_names() %>% filter(episodes > 1)

# setdiff(ids_recurrent$patient_name, peru_recurrent$patient_name)
# setdiff(peru_recurrent$patient_name, ids_recurrent$patient_name)

# peru_recurrent %>% distinct(sample_id) %>% arrange(sample_id) # 87 isolates
```

### Data on episode number and time since last episode
```{r episode summary}
episode_summary <- peru_recurrent %>% 
  distinct(patient_name, date, sample_id, day) %>% 
  mutate(date = mdy(date)) %>%
  arrange(patient_name, date) %>% 
  group_by(patient_name) %>% 
  mutate(
    # get the episode number
    episode_number = row_number(),
    # calculate days since enrolment, just a check with dates
    days_since_enrolment = as.integer(date - min(date[day == "Day 0"])),
    # calculate days since last episode using lag() and making enrolment episodes 0 days since last
    days_since_last_episode = replace_na(as.integer(date - lag(date)), 0)
  ) %>% 
  ungroup()
```

Note that in the Peru study this is not necessarily a person's "first" episode, rather the first episode in the evaluated study period
```{r plot recurrences, fig.height=8, fig.width=8}
episode_summary %>% 
  distinct(patient_name, sample_id, days_since_enrolment) %>%
  ggplot(aes(x = days_since_enrolment, y = reorder(patient_name, days_since_enrolment))) +
    geom_line(aes(group = patient_name), color = "darkgrey") +
    geom_point() +
    labs(x = "Days since first episode during study period",
         y = "Participant") +
    theme_bw() 
```

### "Null distribution"
To understand the false discovery rate (FDR), we will 'jumble up' the pairs of recurrences so that they are matched to the wrong baseline episode and recurrent episode (i.e. in different people) and then run `compute_posterior()` to see what the Pr(false recrudescence) and Pr(false relapse) based on our dataset.

First will start with the simplest random pairing:

- every baseline episode will have one recurrent episode pair at random (based on all possible recurrent episodes (n=X))

There are 40 participants (X had only the baseline episode and X of them had at least 1 recurrent episode during follow-up).
```{r}
peru_all_patients <- peru %>%
        clean_names() %>% 
        select(sample, info = patient_name, date, episode_type = day, episodes) %>% 
        distinct() %>% 
        arrange(sample) %>% 
        mutate(date = mdy(date))

peru_all_patients %>% 
  distinct(info, episodes) %>%
  ggplot(aes(x = episodes)) +
    geom_bar() +
    scale_x_continuous(breaks = scales::pretty_breaks(n=5)) +
    theme_bw()
```

```{r fxn to randomize pairs peru}
randomize_pairs_partial <- function(data, max_attempts = 100) {
  attempt <- 1
  
  repeat {
    # Shuffle
    shuffled_data <- data %>%
      mutate(rand_order = sample(n())) %>%
      arrange(rand_order) %>%
      select(-rand_order) %>%
      mutate(pair_index = ceiling(row_number() / 2))
    
    # Keep only pairs that meet constraints
    valid_pairs <- shuffled_data %>%
      group_by(pair_index) %>%
      filter(n() == 2) %>%
      mutate(
        date1 = first(date),
        date2 = last(date),
        info1 = first(info),
        info2 = last(info)
      ) %>%
      filter(date1 < date2 & info1 != info2) %>%
      ungroup()
    
    if (nrow(valid_pairs) > 0) {
      # Found at least some pairs, return them
      valid_pairs <- valid_pairs %>%
        mutate(shuffled_pair_id = paste0("NewID-", pair_index))
      
      return(valid_pairs)
    } else {
      # If we found no valid pairs, try again
      attempt <- attempt + 1
      if (attempt > max_attempts) {
        stop("Couldn't form any valid pairs after multiple attempts.")
      }
    }
  }
}

```

```{r randomize pairs}  
random_pairs <- randomize_pairs_partial(peru_all_patients)

# check again that we haven't randomly matched to the same patient!
# random_pairs %>%
#   group_by(shuffled_pair_id) %>%
#   filter(n_distinct(info) < n()) %>%
#   summarise(duplicate_info = list(info)) %>%
#   ungroup()
```

Merge back with full dataset
```{r merge with full}
peru_recurrent_null <- random_pairs %>% 
  left_join(peru %>% clean_names() %>% mutate(date = mdy(date)), by = c("sample", "info" = "patient_name", "date", "episodes")) 
```

### Data on episode number and time since last episode for new shuffled pairs
Note that in the Peru study this is not necessarily a person's "first" episode, rather the first episode in the evaluated study period

```{r episode summary null}
episode_summary_null <-peru_recurrent_null %>%
  distinct(shuffled_pair_id, day, date, sample) %>%
  arrange(shuffled_pair_id, date) %>%
  group_by(shuffled_pair_id) %>%
  mutate(
    # get the episode number
    episode_number = row_number(),
    first_date = first(date),
    second_date = last(date),
    days_since_last_episode = as.integer(last(date) - first(date))
  ) %>%
  ungroup()
```

Note that in the Peru study this is not necessarily a person's "first" episode, rather the first episode in the evaluated study period
```{r plot recurrences, fig.height=8, fig.width=8}
episode_summary_null %>% 
  ggplot(aes(x = days_since_last_episode, y = reorder(shuffled_pair_id, days_since_last_episode))) +
    geom_line(aes(group = shuffled_pair_id), color = "darkgrey") +
    geom_point() +
    labs(x = "Days since first episode during study period",
         y = "Participant") +
    theme_bw() 
```

## Haplotype frequencies
We want to remove any haplotypes that appear only once at very low frequencies. Haplotypes should already be filtered to be observed in at least 2 samples and within-host frequency >=1% (in full dataset).

```{r singletons}
singleton_haps <- peru_recurrent_null %>% 
  select(sample, marker_id, haplotype, frequency, count) %>% 
  count(haplotype) %>% 
  arrange(n) %>% 
  filter(n==1) %>% 
  pull(haplotype)

peru_recurrent %>%
  filter(haplotype %in% singleton_haps) %>%
  ggplot(aes(x = haplotype, y = count)) +
    geom_hline(yintercept = 100, linetype = "dashed") +
    geom_point(aes(color = frequency, shape = day), size = 3) +
    labs(x = "singleton haplotype",
         y = "read count",
         color = "within-sample frequency",
         shape = "timepoint") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

## Haplotypes for inference
For Peru, most recurrences would be expected to be either reinfections or relapses, given that this study was an observational community cohort in two sites in Peru. As per Aimee's suggestion, we can estimate population-level allele frequencies based on all episodes in our dataset (we will use the entire dataset (n=93 participants), not just those the subset that experienced recurrences (n=40). This should be unbiased as both reinfections and relapses are draws from the mosquito population (relapses would be time-lagged draws) in the absence of any systematic within-patient selection of recrudescent parasites.
```{r haps for inference}
# n=718 haps
all_haps <- peru_recurrent_null %>% 
  pull(haplotype)

peru_recurrent_null %>%
  select(sample, marker_id, haplotype, frequency, count) %>%
  arrange(frequency, count)
```

## Final data for inference
```{r final analysis data}
analysis_data <- peru_recurrent_null %>%
  select(subject_id = shuffled_pair_id, # using "new ID" instead of original participant ID
         sample_id = sample, 
         visit_date = date,
         age_years = age, 
         sex, 
         # episodes, # this is not accurate anymore
         marker_id, 
         haplotype, 
         frequency,
         mean_moi,
         max_moi) %>% 
  # add extra epi info on episode number and time since last episode
  left_join(episode_summary_null %>% select(subject_id = shuffled_pair_id, 
                                       sample_id = sample,
                                       episode_number, days_since_last_episode),
            by = c("subject_id", "sample_id")) 
```

### Population-level allele frequencies
```{r baseline allele freqs}
## Derive pop-level allele frequency - This is modified from Thomas/Jason script for our data

# Use data from the entire dataset
fs <- analysis_data %>% 
  
  # split data frame by marker
  group_by(marker_id) %>% 
  group_split() %>% 
  
  # Derive a within-marker list of frequencies, by individual
  lapply(function(x) {
    x <- x %>% 
      # Build a within-individual frequency table that 
      # always includes every haplotype (even the ones absent)
      mutate(haplotype = factor(haplotype)) %>% 
      select(sample_id, haplotype, frequency) %>% 
      pivot_wider(names_from = haplotype, 
                  values_from = frequency, 
                  values_fill = 0) %>% 
      pivot_longer(cols = -sample_id, 
                   names_to = "haplotype", 
                   values_to = "frequency") %>% 
      # Get population-level haplotype frequency, 
      # correcting for when within-individual sum is not equal 
      # to 1, as can happen when a minority clone is <2%
      group_by(sample_id) %>% 
      mutate(frequency = frequency / sum(frequency, na.rm = TRUE)) %>% 
      group_by(haplotype) %>% 
      summarise(frequency_pop_mean = mean(frequency, na.rm = TRUE))
    
    return(deframe(x))
  }) %>% 
  # get marker_id from group_keys from the group dfs 
  setNames(nm = analysis_data %>% group_by(marker_id) %>% group_keys() %>% pull(marker_id))

# Here we can also save as dataframe for easier printing and table-ready for paper
fs_df <- analysis_data %>% 
  
  # Group by marker_id and sample_id for further calculations
  group_by(marker_id, sample_id) %>% 
  
  # Build a within-individual frequency table that always includes every haplotype (even the ones absent)
  mutate(haplotype = factor(haplotype)) %>% 
  select(marker_id, sample_id, haplotype, frequency) %>% 
  pivot_wider(names_from = haplotype, values_from = frequency, values_fill = list(frequency = 0)) %>% 
  pivot_longer(cols = -c(marker_id, sample_id), names_to = "haplotype", values_to = "frequency") %>% 
  
  # Get population-level haplotype frequency, correcting for when within-individual sum is not equal to 1
  group_by(marker_id, sample_id) %>% 
  mutate(frequency = frequency / sum(frequency, na.rm = TRUE)) %>% 
  group_by(marker_id, haplotype) %>% 
  summarise(frequency_pop_mean = mean(frequency, na.rm = TRUE), .groups = 'drop') %>% 
  
  # Ensure haplotypes are correctly associated with their marker_id - note that this works for us because , in future would have to make this flexible to allow for haplotype names that are not reliant on having marker_id
  filter(str_detect(haplotype, marker_id))

# fs_df
```

## Pv3Rs
### Example on one participant
```{r pv3rs one example}
# This has been modified from Thomas/Jason script 

## Pick an individual at random to run Pv3Rs
# indiv_name <- sample(unique(analysis_data$subject_id), size = 1)
indiv_name <- "NewID-31"

## Prepare the data
# 1- Subset haplotype data to specific individual and apply filters
indiv_haplotype_data <- analysis_data %>% 
  # Restrict to a single patient
  filter(subject_id == indiv_name) %>% 
  # Restrict to a subset of markers, if needed
  filter(marker_id %in% BENCHMARK_MARKERS) %>% 
  # Restrict to summed MOI below threshold
  group_by(subject_id, episode_number, marker_id) %>% 
  mutate(MOI_per_marker = sum(n())) %>% 
  group_by(subject_id, episode_number) %>% 
  mutate(MOI_per_episode = max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(marker_id = factor(marker_id, levels = BENCHMARK_MARKERS))

# 2- Calculate per-episode and per-participant MOI for PvR3S eligibility
indiv_MOI <- indiv_haplotype_data %>% 
  select(subject_id, episode_number, 
         marker_id, starts_with("MOI_")) %>% 
  distinct() %>% 
  group_by(subject_id, episode_number) %>% 
  # Get highest per-marker MOI only for each episode
  # (drop marker_id in case of ties with highest per-marker MOI)
  select(-marker_id) %>% 
  distinct() %>% 
  filter(MOI_per_marker == max(MOI_per_marker, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(MOI_summed = sum(MOI_per_episode, na.rm = TRUE))
```

Prepare test data
```{r}
# Finish data preparation
  indiv_haplotype_data <- indiv_haplotype_data %>% 
    group_by(episode_number) %>% 
    group_split() %>% 
    lapply(function(x) {
      res <- x %>% 
        select(sample_id, episode_number, 
               marker_id, haplotype, frequency) %>% 
        # For sensitivity analysis, allow to include/drop allele 
        # based on their within-individual frequency
        filter(frequency >= WITHIN_INDIVIDUAL_ALLELE_FREQ_THR) %>% 
        select(-sample_id, -episode_number, -frequency) %>% 
        distinct() %>% 
        # Prevent dropping of markers that are not characterised 
        # by setting .drop to FALSE
        group_by(marker_id, .drop = FALSE) %>% 
        group_split() %>% 
        lapply(function(y) {
          unique(y$haplotype)
        })
      
      # Returned a list named with each episode, 
      # setting marker allele to NA in case none are observed
      return(lapply(setNames(res, BENCHMARK_MARKERS), 
                    function(y) {
                      if (length(y) == 0) return(NA) else return(y)
                    }))
    })
```

```{r run compute posterior one indiv}
# Run Aimee's posterior estimation
indiv_posterior <- Pv3Rs::compute_posterior(y  = indiv_haplotype_data, 
                                            fs = fs[BENCHMARK_MARKERS])

indiv_posterior
```

The joint posterior probability of reinfection is 0.77%, but the model finds probability of relapse to be 22.6% (false positive).
```{r plot haps}
peru_recurrent_null %>% 
  filter(shuffled_pair_id == "NewID-31") %>% 
  ggplot(aes(x = haplotype, y = factor(episode_type), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free_x") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```
### Run for all participants
```{r run pv3rs all}
# Start timer
t_start <- Sys.time()

# Initialize an empty list to store the results
indiv_posteriors <- list()

# Loop through each unique individual name
for (indiv_name in unique(analysis_data$subject_id)) {
  # Verbose
  cat("ID : ", indiv_name, "...\n", sep = "")
  
  ## Prepare the data
  # 1- Subset haplotype data to specific individual and apply filters
  indiv_haplotype_data <- analysis_data %>% 
    # Restrict to a single patient
    filter(subject_id == indiv_name) %>% 
    # Ensure episodes are in order
    arrange(episode_number) %>%  
    # Restrict to a subset of markers
    filter(marker_id %in% BENCHMARK_MARKERS) %>% 
    # Restrict to summed MOI below threshold
    group_by(subject_id, episode_number, marker_id) %>% 
    mutate(MOI_per_marker = sum(n())) %>% 
    group_by(subject_id, episode_number) %>% 
    mutate(MOI_per_episode = max(MOI_per_marker, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(marker_id = factor(marker_id, levels = BENCHMARK_MARKERS))
  
  # 2- Calculate per-episode and per-participant MOI for PvR3S eligibility
  indiv_MOI <- indiv_haplotype_data %>% 
    select(subject_id, episode_number, 
           marker_id, starts_with("MOI_")) %>% 
    distinct() %>% 
    group_by(subject_id, episode_number) %>% 
    # Get highest per-marker MOI only for each episode
    # (drop marker_id in case of ties with highest per-marker MOI)
    select(-marker_id) %>% 
    distinct() %>% 
    filter(MOI_per_marker == max(MOI_per_marker, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(MOI_summed = sum(MOI_per_episode, na.rm = TRUE))
  
  ## Run Pv3Rs only if MOI below threshold         
  if (unique(indiv_MOI$MOI_summed) <= MAX_MOI_TO_INCLUDE) {
    # Verbose
    cat("Running Pv3Rs for: ", 
        indiv_name, 
        " (summed MOI = ", 
        unique(indiv_MOI$MOI_summed), 
        ").\n", 
        sep = "")
    
    # Preserve episode numbers for naming the output list
    indiv_episode <- unique(indiv_haplotype_data$episode_number)
    cat("The episode number is: ", indiv_episode) # printing to check episode order number is correct
    
    # Finish data preparation
    indiv_haplotype_data <- indiv_haplotype_data %>% 
      group_by(episode_number) %>% 
      group_split() %>% 
      lapply(function(x) {
        res <- x %>% 
          select(sample_id, episode_number, 
                 marker_id, haplotype, frequency) %>% 
          # For sensitivity analysis, allow to include/drop allele 
          # based on their within-individual frequency
          filter(frequency >= WITHIN_INDIVIDUAL_ALLELE_FREQ_THR) %>% 
          select(-sample_id, -episode_number, -frequency) %>% 
          distinct() %>% 
          # Prevent dropping of markers that are not characterized 
          # by setting .drop to FALSE
          group_by(marker_id, .drop = FALSE) %>% 
          group_split() %>% 
          lapply(function(y) {
            unique(y$haplotype)
          })
        
        # Returned a list named with each episode, 
        # setting marker allele to NA in case none are observed
        return(lapply(setNames(res, BENCHMARK_MARKERS), 
                      function(y) {
                        if (length(y) == 0) return(NA) else return(y)
                      }))
      })
    
    # Run Aimee's posterior estimation
    indiv_posterior <- compute_posterior(y     = indiv_haplotype_data,
                                         fs    = fs[BENCHMARK_MARKERS], 
                                         prior = matrix(PRIOR_3RS, 
                                                        nrow     = length(indiv_haplotype_data), 
                                                        ncol     = length(PRIOR_3RS), 
                                                        byrow    = TRUE, 
                                                        dimnames = list(c(1:length(indiv_haplotype_data)), 
                                                                        names(PRIOR_3RS))))
    
  } else {
    # Verbose
    cat("NOT Running Pv3Rs for: ", 
        indiv_name, 
        " because summed MOI exceeds threshold (observed = ", 
        unique(indiv_MOI$MOI_summed), 
        ", MAX_MOI_TO_INCLUDE = ", 
        MAX_MOI_TO_INCLUDE, 
        ").\n", 
        sep = "")
    
    # Return NULL
    indiv_episode    <- unique(indiv_haplotype_data$episode_number)
    indiv_posterior <- NULL
  }
  
  # Append the results to the list
  indiv_posteriors[[indiv_name]] <- list("subject_id" = indiv_name, 
                                         "episode_number"       = indiv_episode, 
                                         "Pv3Rs"       = indiv_posterior)
}

# End timer
t_end <- Sys.time()
cat("Pv3Rs for the whole dataset took : ", as.numeric(difftime(time1 = t_end, 
                                                               time2 = t_start, 
                                                               units = "secs"))/60, " mins", "\n", sep = "")

# Present the marginal data in a clearer format
indiv_posteriors_marginal <- do.call(rbind, 
                                     lapply(indiv_posteriors, function(x) {
                                       if (!is.null(x[["Pv3Rs"]])) {
                                         return(data.frame("subject_id"               = x[["subject_id"]], 
                                                           "episode_number"                     = x[["episode_number"]][-1], 
                                                           "Posterior_marginal_prob_C" = x[["Pv3Rs"]]$marg[, "C"], 
                                                           "Posterior_marginal_prob_L" = x[["Pv3Rs"]]$marg[, "L"], 
                                                           "Posterior_marginal_prob_I" = x[["Pv3Rs"]]$marg[, "I"]))
                                       } else {
                                         return(NULL)
                                       }
                                       
                                     }))
row.names(indiv_posteriors_marginal) <- 1:nrow(indiv_posteriors_marginal)

# Present the joint posterior estimates in a clearer format
indiv_posteriors_joint <- do.call(rbind, 
                                  lapply(indiv_posteriors, function(x) {
                                    if (!is.null(x[["Pv3Rs"]])) {
                                      joint_probs <- x[["Pv3Rs"]]$joint
                                      # Extract the state pairs and probabilities
                                      state_pairs <- names(joint_probs)
                                      prob_values <- as.numeric(joint_probs)
                                      
                                      # Create a data frame with subject_id, episode_number, and joint probabilities
                                      return(data.frame("subject_id"      = rep(x[["subject_id"]], length(state_pairs)), 
                                                        "episode_number"  = rep(x[["episode_number"]][-1], each = length(state_pairs)),
                                                        "state_pair"      = state_pairs, 
                                                        "joint_probability" = prob_values))
                                    } else {
                                      return(NULL)
                                    }
                                  }))
row.names(indiv_posteriors_joint) <- 1:nrow(indiv_posteriors_joint)

# Save Pv3Rs output because it's time consuming and 
# we don't want to re-run it every time.
save(list = c("RUN_EXAMPLE", "WITHIN_INDIVIDUAL_ALLELE_FREQ_THR", "BENCHMARK_MARKERS", "MAX_MOI_TO_INCLUDE", "PRIOR_3RS", 
              "analysis_data", "fs", 
              "indiv_posteriors", "indiv_posteriors_marginal", "indiv_posteriors_joint"), 
     file = paste0("./outputs/Pv3Rs_peru_posteriors_null_distribution_", 
                   strftime(Sys.time(), format = "%Y%m%d_%H%M%S"), 
                   ".RData"))
```

### Explore the posterior
The marginal probabilities give us the probability of the three states for each recurrent episode. However, this does not consider the joint probability of different states when a person experienced more than one recurrent episode. 
```{r marginal probs}
indiv_posteriors_marginal
```

The joint probabilites give us values for each possible combination of states, depending on the number of recurrent episodes experienced by the participant. 
```{r joint probs}
joint_summary <- indiv_posteriors_joint %>% 
                    group_by(subject_id, state_pair, joint_probability) %>% 
                    filter(episode_number == max(episode_number)) %>% 
                    mutate(percentage = round(joint_probability*100, 3),
                           total_recurrences = episode_number-1) %>%
                    select(-episode_number) %>% 
                    arrange(subject_id, total_recurrences, percentage) %>% 
                    relocate(total_recurrences, .before = state_pair)

joint_summary
```

## Plot marginal probabilities 
```{r marg probs}
marginal_summary <- indiv_posteriors_marginal %>% 
  pivot_longer(cols = !subject_id & !episode_number, 
               names_to = "posterior_type", 
               values_to = "posterior_value") %>% 
  mutate(posterior_classification = case_when(posterior_type == "Posterior_marginal_prob_C" ~ "Recrudescence",
                                              posterior_type == "Posterior_marginal_prob_L" ~ "Relapse",
                                              posterior_type == "Posterior_marginal_prob_I" ~ "Reinfection"),
         posterior_classification = factor(posterior_classification, 
                                           levels = c("Relapse", "Recrudescence", "Reinfection"))) %>% 
  select(-posterior_type)

marginal_summary
```

### By shuffled pair ID
```{r plot probabilities, fig.height=8, fig.width=8}
marginal_summary %>% 
  group_by(subject_id) %>%
  arrange(desc(posterior_value), .by_group = TRUE) %>%
  mutate(subject_id = factor(subject_id, levels = unique(subject_id[order(posterior_value, decreasing = TRUE)]))) %>%
  
  ggplot(aes(x = factor(episode_number), y = posterior_value, group = episode_number, fill = posterior_classification)) + 
    geom_bar(stat = "identity", position = "fill") +
    scale_fill_manual(values = c("Relapse" = "turquoise3",
                                 "Recrudescence" = "skyblue4",
                                 "Reinfection" = "magenta3")) +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    labs(x     = "Episode number", 
         y     = "Posterior probability", 
         fill = "") + 
    theme_bw() +
    facet_wrap(~subject_id)
```

```{r plot fdr}
marginal_summary %>% 
  group_by(subject_id) %>%
  filter(posterior_classification == "Reinfection") %>% 
  mutate(fdr = 1-posterior_value) %>% 
  ggplot(aes(x = reorder(subject_id, fdr), y = fdr)) +
    geom_col() +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    labs(x = "Shuffled pair ID", 
         y = "False discovery rate (%)",
         caption = "FDR calculated as 1 - Pr(recrudescence)+Pr(relapse)") + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) 
```

## Summarize false discovery rate (FDR)

```{r fdr}
marginal_summary %>% 
  group_by(posterior_classification) %>% 
  summarise(min = min(posterior_value),
            mean = mean(posterior_value),
            max = max(posterior_value))
```

```{r fdr}
marginal_summary %>% 
  group_by(subject_id) %>%
  filter(posterior_value == max(posterior_value)) %>%
  ungroup() %>% 
  tabyl(posterior_classification) %>% 
  adorn_totals()
```

Checking the worst IDs (NewID-35, 48 and 64)
```{r}
peru_recurrent_null %>% 
  filter(shuffled_pair_id == "NewID-35") %>% 
  ggplot(aes(x = haplotype, y = factor(episode_type), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

peru_recurrent_null %>% 
  filter(shuffled_pair_id == "NewID-48") %>% 
  ggplot(aes(x = haplotype, y = factor(episode_type), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

peru_recurrent_null %>% 
  filter(shuffled_pair_id == "NewID-64") %>% 
  ggplot(aes(x = haplotype, y = factor(episode_type), fill = factor(haplotype))) +
  geom_tile() +
    facet_grid(~marker_id, scales = "free") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

